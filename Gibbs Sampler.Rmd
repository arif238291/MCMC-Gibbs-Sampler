---
title: "MCMC Gibbs Sampler Excercise and Solution"
author: 'Md Ariful Islam '
date: "`r format(Sys.time(), '%B %d, %Y')`"
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
header-includes:
- \usepackage{amsfonts}
- \usepackage{fontawesome}
- \usepackage{amsmath}
subtitle: null
geometry: margin=1in
fontsize: 11pt
endnote: no
---



```{r setup, include=FALSE}
# Put any libraries you load here so 
# they do not end up getting printed in the 
# compiled file 
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/mdarifulislam/Desktop/Thesis/GIBBS")
library(tidyverse)
library(palmerpenguins)
```


## Question 1 
Consider the following joint density for 
$$f(\theta) \sim {\theta_2}^{a_0}e^{-a_1\theta_2\theta_3^2+a_2\theta_1\theta_3-a_3\theta_1^2\theta_2-a_4\theta_1}$$

where $a_0, a_1, a_2, a_3, a_4$ are are known constants. We want to do a Gibbs Sampler for drawing samples of $\theta$ using above joint density. Answer the following questions:


(i) If we want to do a Gibbs Sampler using $\theta_1, \theta_2, and \hspace{1 mm} \theta_3$ as three separate blocks, derive the three full conditional distributions.

(ii) If we want to do a Gibbs Sampler using $\begin{bmatrix}\theta_1 \\ \theta_3 \end{bmatrix}$ as one block and $\theta_2$ as another block, derive the two full conditional distributions.

## Answer (i):

The full conditional conditional posterior distribution for $\theta_1|\theta_2, \theta_3$ is
$$\theta_1|\theta_2,\theta_3 \sim N(\frac{a_2\theta_3-a_4}{2a_3\theta_2},\frac{1}{2a_3\theta_2})$$
The full conditional conditional posterior distribution for $\theta_2|\theta_1, \theta_3$ is
$$\theta_2|\theta_1,\theta_3 \sim Gamma(a_0+1,a_1\theta_3^2+a_3\theta_1^2)$$
The full conditional conditional posterior distribution for $\theta_3|\theta_1, \theta_2$ is
$$\theta_3|\theta_1, \theta_2 \sim N(\frac{a_2\theta_1}{2a_1\theta_2},\frac{1}{2a_1\theta_2})$$
## Answer (ii):

The full conditional conditional posterior distribution for $\theta_1,\theta_3| \theta_2$ is
$$\theta_1,\theta_3|\theta_2 \sim e^{-a_1\theta_2\theta_3^2+a_2\theta_1\theta_3-a_3\theta_1^2\theta_2-a_4\theta_1}$$

Here, we need Metropolis Hasting algorithm within Gibbs sampler.

The full conditional conditional posterior distribution for $\theta_2|\theta_1, \theta_3$ is
$$\theta_2|\theta_1,\theta_3 \sim Gamma(a_0+1,a_1\theta_3^2+a_3\theta_1^2)$$

## Question 2 

Consider the following joint density for $\theta=\begin{bmatrix}\theta_1 \\ \theta_2 \end{bmatrix}$ with -5<$\theta_1$<2 and 0<$\theta_2$<3
$$f(\theta) \sim e^{-\theta_1^2\theta_2+3\theta_1}$$
We want to do a Gibbs Sampler for drawing samples of $\theta$ using above joint density. If we want to use $\theta_1$, $\theta_2$ as two separate blocks, derive the two full conditional distributions.

## Answer 2

The full conditional conditional posterior distribution for $\theta_1|\theta_2$ is
$$\theta_1|\theta_2 \sim TruncatedNormal(\frac{3}{2\theta_2},\frac{1}{\sqrt(2\theta_2)},-5,2)$$
The full conditional conditional posterior distribution for $\theta_2|\theta_1$ is
$$\theta_2|\theta_1 \sim TruncatedExponential(\theta_1^2,0,3)$$

## Question 3 

Load the single_dataset.Rdata file in R. It contains a vector of observations. Fit the $N(\mu, \sigma^2)$ model to this dataset by estimating the parameters using Gibbs Sampling. Explore four different choices of prior distributions as follows:

(a) $\mu \sim N(20, 10000),\hspace{2 mm} \sigma^2 \sim IG(2.1, 1.5)$

(b) $\mu \sim N(20, 100\sigma^2),\hspace{2 mm} \sigma^2 \sim IG(2.1, 1.5)$

(c) $\pi(\mu) \sim 1,\hspace{2 mm} \pi(\sigma^2) \sim{1/\sigma^2}$

(d) $\mu \sim N(20, 10000),\hspace{2 mm} \sigma^2 \sim LogNormal(0, 100)$


Separately for each case: derive the distributions necessary to implement Gibbs Sampler in pen-and-paper and then, implement them in R. Run for 20000 iterations, discard the first 5000 draws. Do the trace plot as well as histogram for parameter samples.


## Case (a)

```{r}
# Clear the workspace
rm(list = ls())

library(ggplot2)

# Load the dataset
Observations <-get(load("single_dataset.Rdata"))

gibbs_sampling_a <- function(data, n_iter, burn_in, mu_init, alpha_0, beta_0) {
  n <- length(data[[1]])
  mu_samples <- numeric(n_iter)
  sigma2_samples <- numeric(n_iter)
  mu=mu_init
  
  for (i in 1:n_iter) {
    
    # Sample sigma2 from the conditional posterior
    post_alpha <- alpha_0 + n / 2
    post_beta <- beta_0 + sum((data[[1]] - mu)^2) / 2
    sigma2 <- 1 / rgamma(1, shape = post_alpha, rate = post_beta)
    
    # Sample mu from the conditional posterior
    nume_1<-n*mean(data[[1]])/sigma2+ 20/10000
    deno_1<-n/sigma2+1/10000
    mu_norm <- nume_1 / deno_1
    sigma2_norm <- 1/deno_1
    mu <- rnorm(1, mean = mu_norm, sd = sqrt(sigma2_norm))
    

    # Store the samples
    mu_samples[i] <- mu
    sigma2_samples[i] <- sigma2
  }
  
  # Discard burn-in samples
  mu_samples <- mu_samples[(burn_in + 1):n_iter]
  sigma2_samples <- sigma2_samples[(burn_in + 1):n_iter]
  
  list(mu_samples = mu_samples, sigma2_samples = sigma2_samples)
}

# Parameters for Gibbs Sampling
n_iter <- 20000
burn_in <- 5000
mu_0<-0
alpha_0 <- 2.1
beta_0 <- 1.5

# Run Gibbs Sampling 
samples_a <- gibbs_sampling_a(data=Observations, n_iter, burn_in, mu_0, alpha_0, beta_0)

# Extract the samples
mu_samples_a <- samples_a$mu_samples
sigma2_samples_a <- samples_a$sigma2_samples


# Plot the results
par(mfrow = c(2, 2))
plot(mu_samples_a, type = 'l', main = expression(mu), ylab = "Value")
hist(mu_samples_a, main = expression(mu), xlab = "Value", freq = FALSE)
plot(sigma2_samples_a, type = 'l', main = expression(sigma^2), ylab = "Value")
hist(sigma2_samples_a, main = expression(sigma^2), xlab = "Value", freq = FALSE)
```


## Case (b)
```{r}
library(ggplot2)
rm(list = ls())
# Load the dataset
Observations <-get(load("single_dataset.Rdata"))

gibbs_sampling_a <- function(data, n_iter, burn_in, mu_init, alpha_0, beta_0) {
  n <- length(data[[1]])
  mu_samples <- numeric(n_iter)
  sigma2_samples <- numeric(n_iter)
  mu=mu_init
  
  for (i in 1:n_iter) {
    
    # Sample sigma2 from the conditional posterior
    post_alpha <-n / 2+0.5+alpha_0
    post_beta <- beta_0 + sum((data[[1]] - mu)^2) / 2+200^-1*(mu-20)^2
    sigma2 <- 1 / rgamma(1, shape = post_alpha, rate = post_beta)
    
    # Sample mu from the conditional posterior
    nume_1<-sum(data[[1]])+5^-1
    deno_1<-n+100^-1
    mu_norm <- nume_1 / deno_1
    sigma2_norm <-sigma2/(n+100^-1) 
    mu <- rnorm(1, mean = mu_norm, sd = sqrt(sigma2_norm))
    

    # Store the samples
    mu_samples[i] <- mu
    sigma2_samples[i] <- sigma2
  }
  
  # Discard burn-in samples
  mu_samples <- mu_samples[(burn_in + 1):n_iter]
  sigma2_samples <- sigma2_samples[(burn_in + 1):n_iter]
  
  list(mu_samples = mu_samples, sigma2_samples = sigma2_samples)
}

# Parameters 
n_iter <- 20000
burn_in <- 5000
mu_init<-0
alpha_0 <- 2.1
beta_0 <- 1.5

# Run Gibbs Sampling 
samples_a <- gibbs_sampling_a(data=Observations, n_iter, burn_in, mu_init, alpha_0, beta_0)

# Extract the samples
mu_samples_b <- samples_a$mu_samples
sigma2_samples_b <- samples_a$sigma2_samples

# Plot the results
par(mfrow = c(2, 2))
plot(mu_samples_b, type = 'l', main = expression(mu), ylab = "Value")
hist(mu_samples_b, main = expression(mu), xlab = "Value", freq = FALSE)
plot(sigma2_samples_b, type = 'l', main = expression(sigma^2), ylab = "Value")
hist(sigma2_samples_b, main = expression(sigma^2), xlab = "Value", freq = FALSE)
```

## Case (c)
```{r}
library(ggplot2)
rm(list = ls())
# Load the dataset
Observations <-get(load("single_dataset.Rdata"))

gibbs_sampling_a <- function(data, n_iter, burn_in, mu_init) {
  n <- length(data[[1]])
  mu_samples <- numeric(n_iter)
  sigma2_samples <- numeric(n_iter)
  mu=mu_init
  
  for (i in 1:n_iter) {
    
    # Sample sigma2 from the conditional posterior
    post_alpha <-n/2
    post_beta <- sum((data[[1]] - mu)^2)/2
    sigma2 <- 1 / rgamma(1, shape = post_alpha, rate = post_beta)
    
    # Sample mu from the conditional posterior
    mu_norm <- mean(data[[1]])
    sigma2_norm <-sigma2/n 
    mu <- rnorm(1, mean = mu_norm, sd = sqrt(sigma2_norm))
    

    # Store the samples
    mu_samples[i] <- mu
    sigma2_samples[i] <- sigma2
  }
  
  # Discard burn-in samples
  mu_samples <- mu_samples[(burn_in + 1):n_iter]
  sigma2_samples <- sigma2_samples[(burn_in + 1):n_iter]
  
  list(mu_samples = mu_samples, sigma2_samples = sigma2_samples)
}

# Parameters 
n_iter <- 20000
burn_in <- 5000
mu_init<-0

# Run Gibbs Sampling 
samples_a <- gibbs_sampling_a(data=Observations, n_iter, burn_in, mu_init)

# Extract the samples
mu_samples_c <- samples_a$mu_samples
sigma2_samples_c <- samples_a$sigma2_samples

# Plot the results
par(mfrow = c(2, 2))
plot(mu_samples_c, type = 'l', main = expression(mu), ylab = "Value")
hist(mu_samples_c, main = expression(mu), xlab = "Value", freq = FALSE)
plot(sigma2_samples_c, type = 'l', main = expression(sigma^2), ylab = "Value")
hist(sigma2_samples_c, main = expression(sigma^2), xlab = "Value", freq = FALSE)
```
## Case(d)
```{r}

# Clear the workspace
rm(list = ls())

library(ggplot2)

# Load the dataset
Observations <-get(load("single_dataset.Rdata"))


mcmc <- function(data, mu_init,init_sigma2, iterations, proposal_sd) {
  proposed_sigma2 <- numeric(iterations)
  proposed_sigma2[1] <- init_sigma2
  accepted_proposal <- 0
  
  n <- length(data)
  mu_samples <- numeric(iterations)
  sigma2_samples <- numeric(iterations)
  mu<-mu_init
  sigma2<-var(data)
  
  for (i in 1:iterations) {
    proposed_sigma2 <- rlnorm(1, mean =log(sigma2) , sd = proposal_sd)
    log_target_current<--(n/2+1)*log(sigma2)-0.5*sum((data-mu)^2)/sigma2-0.5*(log(sigma2)-0)^2/100
    log_target_proposed<--(n/2+1)*log(proposed_sigma2)-0.5*sum((data-mu)^2)/proposed_sigma2-0.5*(log(proposed_sigma2)-0)^2/100
    
  
    log_ratio_target<-log_target_proposed-log_target_current
    log_ratio_proposal<-log(proposed_sigma2)-log(sigma2)
    
   
    log_acceptance_ratio<-log_ratio_target+log_ratio_proposal
    
    if (log(runif(1)) < log_acceptance_ratio) {
      sigma2 <- proposed_sigma2
      accepted_proposal <- accepted_proposal + 1
    }
    # Sample mu from the conditional posterior
    nume_1<-n*mean(data)/sigma2+ 20/10000
    deno_1<-n/sigma2+1/10000
    mu_norm <- nume_1 / deno_1
    sigma2_norm <- 1/deno_1
    mu <- rnorm(1, mean = mu_norm, sd = sqrt(sigma2_norm))
  
    # Store the mu and sigma2 samples
    mu_samples[i] <- mu
    sigma2_samples[i]=sigma2
  }
  

  return(list(mu_samples = mu_samples,sigma2_samples = sigma2_samples, accepted_proposal = accepted_proposal))
}

#  using proposal variance = 0.25
# Set parameters
mu_init<-0
init_sigma2 <-var(Observations[[1]])
iterations <- 20000
proposal_sd <- sqrt(0.25)

# Run the MCMC algorithm
results <- mcmc(Observations[[1]],mu_init,init_sigma2, iterations, proposal_sd)
# Extract the samples
mu_samples_d <- results$mu_samples
sigma2_samples_d <- results$sigma2_samples

# Plot the results
par(mfrow = c(2, 2))
plot(mu_samples_d, type = 'l', main = expression(mu), ylab = "Value")
hist(mu_samples_d, main = expression(mu), xlab = "Value", freq = FALSE)
plot(sigma2_samples_d, type = 'l', main = expression(sigma^2), ylab = "Value")
hist(sigma2_samples_d, main = expression(sigma^2), xlab = "Value", freq = FALSE)

```


